kubernetes : Containerasation Management ,vertical & horizontal scaling , command line & GUI interface,
Architecture 
How to Deploy : 2 vm's---1 master and 1 slave
master should have atleast 2 core cpu's & 4GB RAM
Nodes  should have atleast 1 core CPU & 4GB RAM ,ubuntu O.S
On Master 
ifconfig--- finding IP address of the master machine
sudo kubeadm init--pod-network-cidr=<> --apiserver-advertise-address=<ip-address-of-master>
//For starting a Calico CNI : 192.168.0.0/16 or For starting a plannel CNI : 10.244.0.0/16
// copy the kubeadm token generated on the terminal -----helpful for joining the nodes or connecting slave to the master

U will find the 3 commands on the terminal like to start using your cluster,you need to run the following as aregular user---copy that commands  and paste it in the same page of the master

// For creating a POD based on Calico
//want to know the nodes
kubectl get nodes
//Want to know the PODS
kubectl get pods --all-namespaces -o wide
//For Creating the dashboard first - bring this up before starting or joining the Nodes
// To enable Proxy and continues with new terminal window
kubectl proxy
copy the ip address and paste it website like localhost:8001
//For dashboard create the service account
kubectl create serviceaccount dashboard -n default
//Role Binding
kubectl create clusterrolebinding dashboard-admin -n default \
 --clusterrole=cluster-admin \
 --serviceaccount=default:dashboard
 //To get the secret key to be pasted into the dashboard token pwd,copy the outcoming secrete key
 we will get the token generated in master terminal and paste in the localhost:8001------- and then login is accessible to kubernetes dashboards
 open node terminal---master IP paste in the node terminal
 IN Dashboard---we can see master and nodes
 //How to deploy the apps  by using the GUI in dashboard---Create an app---app name--nginx(container image)--no of pods(Containers)--1/2 ---External--port no : 82 , 80--DEPLOY---click on 1 pod--copy the port number and paste in the localhost we will see the page
//HOw to deploy the apps through CLI on master terminal  
//1st create a deployment----> kubectl create deployment nginx --image=nginx
//Verify the deployment --->kubectl get deployments
//more details about the deployment---->kubectl describe deployment nginx
//Create service on the nodes-----> kubectl create service nodeport nginx --tcp=80:80
//To check which deployment is running on which node----> kubectl get svc
//To delete deployment ------> kubectl delete deployment <name>
//Deployment via yaml code 
//write the yaml code in nodepad and save as file in your system
ls
gedit deployment.yaml----file name
//Create a Deployment using Yaml ---> kubectl create -f deployment.yaml

ANSIBLE : Managing multiple servers via configuration management, Auto scalling up or down , Rolling back
Ansible is the configuration management tool like puppet,chef,saltstack
simple to install and setup,NO need of any agent/client software to manage the nodes,capabilites to model complex IT workflows and orchestrate your entire IT infrastructure,Extensible with modules written in any programming language
Ansible Tower : it is web based interface to amnaging enterprise levels




ip addr show --- checking Ip address
hostname -i 
ifconfig
ping ----------checking the server response
ping 8.8.8.8
ping google.com
control+z --- stopping the command
who is domain----getting data about domain
dig domain ----forward lookup
dig -x host ---- reverse lookup
host google.com
active ports ---netstack -pnltu
wget filename ---download the file from online source
hostname -i -------diplays local IP address
changing from file to tar file ----tar -cvf filename.tar filename

here --- filename.tar ----destination
   filename ------source
   
   UNTAR --- changing form tar to normal file
   first do Gzip and the untar
   gzip filename.tar.gz filename.tar
   tar -zxvf filename.tar.gz
   fdisk -l -----listing the disk total space
   free -m ----- view the free space
   df -- mount paoints --- in kbs
   df -Th ---- mount points --- in mbs
   df -i -------i nodes ( the total data stored in the disk is I nodes)
   du -sh ----view the memory usage in kilobytes
   moving from folder to root --- cd/root/
   moving to folder ----cd dir1/  or cd~   or cd
   coming back -- cd ..
   cd ../..
   cd ..\..
   cd c/d/
   cd -    -----going to back to the same path
   
   yum install tree
   tree
   EX: directories : a/b/c/d/e
   come to c dir : cd a/b/c/
   come to a dir : cd ../..
   again back to c dir : cd -
   
   GREP Commands: Global Regular Expression Print --- searching purpose in the files
   grep divya file1  or grep -i divya file1  or cat file1| grep devops  ----o/p: searches the divya word in the file1
   grep -v divya file1 ----o/p:  except that word ,all lines shows in the file
   cat file1| grep devops ----o/p: that devops word lines in the file are excuted
   
   SED Commands : STREAM EDitor
   sed '=' file1 -----o/p: excutes the lines with line numbers i separate lines
   sed -n '3,6p' file1 ----o/p: excutes 3 to 6 lines in the file1
   echo Hi | sed 's/Hi/Hello/' ----chnaging word Hi to Hello 
   sed '3c\kittu' file1 --- To chnage the 3rd line in the  file
   
   Linux Dirctory system:
   FHS : fully hirearchy system
   etc : it contains all the host specific system configuration files
   proc : it is used to see all the processing related files (hardware details)
   home : users home directory
   bin: it stores all the binary files and also it stores the commands that has been excuted by the user
   adduser name
   chnaging password: passwd username
   enter password
   MOving from Root user to divvi user : visudo
   shift+g
   Allow root to run any command anywhere 
   yyp
   divvi   all =all   nopasswd:all
   shift: wq
   su - divvi --- chnaging from root to divvi user
   adding 1 user to another user --- sudo useradd anu
   paasword anu enter
    cloud --- directory ----1.aws dir---- 3files (aws1,aws2,aws3)rwx --aws 1 user and 1 group
                            2.Azure dir ---3 files (az1,az2,az3) rw ---azure 1 user ki owner user  and group ki root owner
                            3. GCP dir --- 3 files (gcp 1,gcp2,gcp3) only write permission -- gcp user ---root ,group owner is GCP
                            
                            
     mkdir clouds
     cd clouds/
     ll
     mkdir aws azure gcp
     cd aws/
     touch aws{1..3}
     ll
     chmod 777 *
     ll
     useradd aws
     chown aws:aws *
     ll
     cd
     create the links 
     ln -s clouds/aws/aws1 aws1
     ll
     ln -s clouds/aws/aws2 aws2
     ll
     ln -s clouds/aws/aws3 aws3
     
     Forget password : ???
     useradd meena
     passwd meena
     123456
     123456
     forget password then
     passwd meena
     again changing the new password
              
   
   
   Jennkins _ Master slave  :                   starting of the master -if connection not happening ---sudo amazon-linux-extras install epel -y
   
   Running from: /usr/share/java/jenkins.war
   cat /etc/passwd
   usernad passwd : passwd jenkins
   
   In SLAVE :
   usr and pwd same steps as in master
   master >  su - jenkins   ----switching to jenkins user
    ssh-keygen --- key gen for connecting nodes
    Generating public/private rsa key pair.
Enter file in which to save the key (/var/lib/jenkins/.ssh/id_rsa):
enter
enter
enter ---public and private keys generates
ls /var/lib/jenkins/.ssh/   ----keys are in this path   id_rsa  id_rsa.pub
ssh-copy-id jenkins@localhost
yes  --- o/p : Number of key(s) added: 1
ssh 'jenkins@localhost'  -- connecting to local host
hostname -i
u will get private ip ---- means master jenkins machine is connected to local machine
exit -----o/p:logout
Connection to localhost closed.
master>ssh-copy-id jenkins@52.14.201.222    ---- connecting slave 1 by using pubic ip slave 1
yes
password of slave 1 password
ssh 'jenkins@slave1 public ip address'
then we will see the slave 1 private ip address means in master slave ip address can be seen so connectin is done with the master and slave

slave2 : useradd jenkins
passwd jenkins
saidivya
visudo
yyp -- copy paste root user
jenkins all nopasswd:all
vim /etc/ssh/sshd_config   --- password authentication yes
systemctl restart sshd
systemctl status sshd
IN master > -bash-4.2$   ssh-copy-id jenkins@slave2 public ip
yes
slave2 password
copy command
ssh 'jenkins:slave2 public ip'
will see the private ip address of slave2

How many slave nodes are connected to master----jnkins GUI -- manage jenkins---manage nodes and clouds---

IN slave to master connection:
su - jenkins
ssh-keygen
enter
enter
enter
jenkins slave>ssh-copy-id jenkins@localhost
key generated
ssh 'jenkins@localhost'
exit
>ssh-copy-id jenkins@master ip address
yes
enter
password : master pwd
ssh jenkins@master public ip address
hostname -i
u will see the master private ip address





AWS console: https://aws.amazon.com/marketplace/partners/management-tour
codingrad : https://learn.codingrad.com/student-login/  ----notes
https://learn.codingrad.com/devops-april-2022/    ----videos
https://hub.docker.com/choose-plan?ref=signup --- username :divyatunuguntla,saidivya550@gmail.com,pwd:Prudhviraj467*









Docker:
cat /etc/os-release
list the containers in ec2 --- docker ps -a   ---- it shows runinng and stopped containers also
create container with new name ---- docker run -it --name divya ubuntu  ------------------------divya container is created with ubuntu image
docker run -it --name divya ubuntu /bin/bash  ---- another way to create container
docker run -it --name divya1 ubuntu /bin/bash
 docker run -it --name divya2  ubuntu touch f1 
 If we wana add any files  and going inside of the container , -- we need to start the container -----> docker start divya1
 docker ps -a
 docker ps
 docker attach divya1 ---- going inside of container divya1
 docker stop divya2 -- stps the container
 docker rm divya1 ---- removes the container
 
 BUILD AN CONTAINER FROM IMAGE:
 docker images
 ex: we have ubuntu image then create a container from image
 docker run -it --name divya ubuntu /bin/bash
 wana create tem file in divya container ---
 



 
   
   

kubernetes : Containerasation Management ,vertical & horizontal scaling , command line & GUI interface,
Architecture 
How to Deploy : 2 vm's---1 master and 1 slave
master should have atleast 2 core cpu's & 4GB RAM
Nodes  should have atleast 1 core CPU & 4GB RAM ,ubuntu O.S
On Master 
ifconfig--- finding IP address of the master machine
sudo kubeadm init--pod-network-cidr=<> --apiserver-advertise-address=<ip-address-of-master>
//For starting a Calico CNI : 192.168.0.0/16 or For starting a plannel CNI : 10.244.0.0/16
// copy the kubeadm token generated on the terminal -----helpful for joining the nodes or connecting slave to the master

U will find the 3 commands on the terminal like to start using your cluster,you need to run the following as aregular user---copy that commands  and paste it in the same page of the master

// For creating a POD based on Calico
//want to know the nodes
kubectl get nodes
//Want to know the PODS
kubectl get pods --all-namespaces -o wide
//For Creating the dashboard first - bring this up before starting or joining the Nodes
// To enable Proxy and continues with new terminal window
kubectl proxy
copy the ip address and paste it website like localhost:8001
//For dashboard create the service account
kubectl create serviceaccount dashboard -n default
//Role Binding
kubectl create clusterrolebinding dashboard-admin -n default \
 --clusterrole=cluster-admin \
 --serviceaccount=default:dashboard
 //To get the secret key to be pasted into the dashboard token pwd,copy the outcoming secrete key
 we will get the token generated in master terminal and paste in the localhost:8001------- and then login is accessible to kubernetes dashboards
 open node terminal---master IP paste in the node terminal
 IN Dashboard---we can see master and nodes
 //How to deploy the apps  by using the GUI in dashboard---Create an app---app name--nginx(container image)--no of pods(Containers)--1/2 ---External--port no : 82 , 80--DEPLOY---click on 1 pod--copy the port number and paste in the localhost we will see the page
//HOw to deploy the apps through CLI on master terminal  
//1st create a deployment----> kubectl create deployment nginx --image=nginx
//Verify the deployment --->kubectl get deployments
//more details about the deployment---->kubectl describe deployment nginx
//Create service on the nodes-----> kubectl create service nodeport nginx --tcp=80:80
//To check which deployment is running on which node----> kubectl get svc
//To delete deployment ------> kubectl delete deployment <name>
//Deployment via yaml code 
//write the yaml code in nodepad and save as file in your system
ls
gedit deployment.yaml----file name
//Create a Deployment using Yaml ---> kubectl create -f deployment.yaml

ANSIBLE : Managing multiple servers via configuration management, Auto scalling up or down , Rolling back
Ansible is the configuration management tool like puppet,chef,saltstack
simple to install and setup,NO need of any agent/client software to manage the nodes,capabilites to model complex IT workflows and orchestrate your entire IT infrastructure,Extensible with modules written in any programming language
Ansible Tower : it is web based interface to amnaging enterprise levels




ip addr show --- checking Ip address
hostname -i 
ifconfig
ping ----------checking the server response
ping 8.8.8.8
ping google.com
control+z --- stopping the command
who is domain----getting data about domain
dig domain ----forward lookup
dig -x host ---- reverse lookup
host google.com
active ports ---netstack -pnltu
wget filename ---download the file from online source
hostname -i -------diplays local IP address
changing from file to tar file ----tar -cvf filename.tar filename

here --- filename.tar ----destination
   filename ------source
   
   UNTAR --- changing form tar to normal file
   first do Gzip and the untar
   gzip filename.tar.gz filename.tar
   tar -zxvf filename.tar.gz
   fdisk -l -----listing the disk total space
   free -m ----- view the free space
   df -- mount paoints --- in kbs
   df -Th ---- mount points --- in mbs
   df -i -------i nodes ( the total data stored in the disk is I nodes)
   du -sh ----view the memory usage in kilobytes
   moving from folder to root --- cd/root/
   moving to folder ----cd dir1/  or cd~   or cd
   coming back -- cd ..
   cd ../..
   cd ..\..
   cd c/d/
   cd -    -----going to back to the same path
   
   yum install tree
   tree
   EX: directories : a/b/c/d/e
   come to c dir : cd a/b/c/
   come to a dir : cd ../..
   again back to c dir : cd -
   
   GREP Commands: Global Regular Expression Print --- searching purpose in the files
   grep divya file1  or grep -i divya file1  or cat file1| grep devops  ----o/p: searches the divya word in the file1
   grep -v divya file1 ----o/p:  except that word ,all lines shows in the file
   cat file1| grep devops ----o/p: that devops word lines in the file are excuted
   
   SED Commands : STREAM EDitor
   sed '=' file1 -----o/p: excutes the lines with line numbers i separate lines
   sed -n '3,6p' file1 ----o/p: excutes 3 to 6 lines in the file1
   echo Hi | sed 's/Hi/Hello/' ----chnaging word Hi to Hello 
   sed '3c\kittu' file1 --- To chnage the 3rd line in the  file
   
   Linux Dirctory system:
   FHS : fully hirearchy system
   etc : it contains all the host specific system configuration files
   proc : it is used to see all the processing related files (hardware details)
   home : users home directory
   bin: it stores all the binary files and also it stores the commands that has been excuted by the user
   adduser name
   chnaging password: passwd username
   enter password
   MOving from Root user to divvi user : visudo
   shift+g
   Allow root to run any command anywhere 
   yyp
   divvi   all =all   nopasswd:all
   shift: wq
   su - divvi --- chnaging from root to divvi user
   adding 1 user to another user --- sudo useradd anu
   paasword anu enter
    cloud --- directory ----1.aws dir---- 3files (aws1,aws2,aws3)rwx --aws 1 user and 1 group
                            2.Azure dir ---3 files (az1,az2,az3) rw ---azure 1 user ki owner user  and group ki root owner
                            3. GCP dir --- 3 files (gcp 1,gcp2,gcp3) only write permission -- gcp user ---root ,group owner is GCP
                            
                            
     mkdir clouds
     cd clouds/
     ll
     mkdir aws azure gcp
     cd aws/
     touch aws{1..3}
     ll
     chmod 777 *
     ll
     useradd aws
     chown aws:aws *
     ll
     cd
     create the links 
     ln -s clouds/aws/aws1 aws1
     ll
     ln -s clouds/aws/aws2 aws2
     ll
     ln -s clouds/aws/aws3 aws3
     
     Forget password : ???
     useradd meena
     passwd meena
     123456
     123456
     forget password then
     passwd meena
     again changing the new password
              
   
   
   Jennkins _ Master slave  :                   starting of the master -if connection not happening ---sudo amazon-linux-extras install epel -y
   
   Running from: /usr/share/java/jenkins.war
   cat /etc/passwd
   usernad passwd : passwd jenkins
   
   In SLAVE :
   usr and pwd same steps as in master
   master >  su - jenkins   ----switching to jenkins user
    ssh-keygen --- key gen for connecting nodes
    Generating public/private rsa key pair.
Enter file in which to save the key (/var/lib/jenkins/.ssh/id_rsa):
enter
enter
enter ---public and private keys generates
ls /var/lib/jenkins/.ssh/   ----keys are in this path   id_rsa  id_rsa.pub
ssh-copy-id jenkins@localhost
yes  --- o/p : Number of key(s) added: 1
ssh 'jenkins@localhost'  -- connecting to local host
hostname -i
u will get private ip ---- means master jenkins machine is connected to local machine
exit -----o/p:logout
Connection to localhost closed.
master>ssh-copy-id jenkins@52.14.201.222    ---- connecting slave 1 by using pubic ip slave 1
yes
password of slave 1 password
ssh 'jenkins@slave1 public ip address'
then we will see the slave 1 private ip address means in master slave ip address can be seen so connectin is done with the master and slave

slave2 : useradd jenkins
passwd jenkins
saidivya
visudo
yyp -- copy paste root user
jenkins all nopasswd:all
vim /etc/ssh/sshd_config   --- password authentication yes
systemctl restart sshd
systemctl status sshd
IN master > -bash-4.2$   ssh-copy-id jenkins@slave2 public ip
yes
slave2 password
copy command
ssh 'jenkins:slave2 public ip'
will see the private ip address of slave2

How many slave nodes are connected to master----jnkins GUI -- manage jenkins---manage nodes and clouds---

IN slave to master connection:
su - jenkins
ssh-keygen
enter
enter
enter
jenkins slave>ssh-copy-id jenkins@localhost
key generated
ssh 'jenkins@localhost'
exit
>ssh-copy-id jenkins@master ip address
yes
enter
password : master pwd
ssh jenkins@master public ip address
hostname -i
u will see the master private ip address





AWS console: https://aws.amazon.com/marketplace/partners/management-tour
codingrad : https://learn.codingrad.com/student-login/  ----notes
https://learn.codingrad.com/devops-april-2022/    ----videos
https://hub.docker.com/choose-plan?ref=signup --- username :divyatunuguntla,saidivya550@gmail.com,pwd:Prudhviraj467*




Docker:


cat /etc/os-release
list the containers in ec2 --- docker ps -a   ---- it shows runinng and stopped containers also
create container with new name ---- docker run -it --name divya ubuntu  ------------------------divya container is created with ubuntu image
docker run -it --name divya ubuntu /bin/bash  ---- another way to create container
docker run -it --name divya1 ubuntu /bin/bash
 docker run -it --name divya2  ubuntu touch f1 
 If we wana add any files  and going inside of the container , -- we need to start the container -----> docker start divya1
 docker ps -a
 docker ps
 docker attach divya1 ---- going inside of container divya1
 docker stop divya2 -- stps the container
 docker rm divya1 ---- removes the container
 
 BUILD AN CONTAINER FROM IMAGE:
 docker images
 ex: we have ubuntu image then create a container from image
 docker run -it --name divya ubuntu /bin/bash
 wana create tem file in divya container ---  cd /tmp/
 cat>divya
 
 hi all hhkjpl ----control+d
 exit
 docker diff divya --o/p: C /root
A /root/.bash_history
C /tmp
A /tmp/divya
 Here: a -- append ,c-change ,d: deletion
 
 Now image1 -----> container (divya file ,some edits happened) ------>Image2 builded ---- then in this image2 --we will see the divya file.
 
 may11 th video:
 
 docker commit divya ubuntu1
 docker images
 docker run -it --name divya ubuntu /bin/bash
     docker diff divya
    docker images
    docker ps
    docker ps -a
    docker commit divya ubuntu
    docker images
    docker commit divya ubuntu1
   docker images
    docker rm ubuntu
    docker ps -a
    docker images
   docker run -it --name divya1 ubuntu1
   docker images
    docker commit divya1 ubuntu1
    docker images
   docker run -it --name divya2 ubuntu1
   
   DOCKER FILE:
   
   image --> container (file --adding,commiting)cd f1---->image
   All this is manual process ,we need to do Automate the process through docker file
   
   text file
   automation of docker image creation
   d is capital in docker file
   starts components also be capital letter
   
 DOCKER FILE COMPONENTS: FROM,RUN,COPY,ADD,EXPOSE,WORKDIR,CMD,ENTRYPOINT,ENV,ARG ......
 COPY : COPYIES THE LOCAL FILES
 ADD: EXTRAS the files from internet and docker
 
 
 
 
 DOCKER FILE CREATION:
 
 CREATE A FILE ----docker file
 IN docker File -----Add instructions
 Build docker file-----to create the docker image
 Run image----to create a container
 
 sudo -i
 sudo yum update -y
 sudo yum install docker -y
 docker --version
 docker version 
 will see only client and host
 systemctl restart docker.service
 systemctl status docker.service
 docker version
 will see the client and server data
 docker images
 docker ps
 docker ps -a
 vim Dockerfile
 FROM ubuntu
 RUN echo " my name is divya" >/tmp/divya
  cat Dockerfile
  
  Creating an image:
  docker build -t image1 .      ------. represents current directory
  o/p:
  Sending build context to Docker daemon  113.3MB
Step 1/2 : FROM ubuntu
latest: Pulling from library/ubuntu
2ab09b027e7f: Pull complete 
Digest: sha256:67211c14fa74f070d27cc59d69a7fa9aeff8e28ea118ef3babc295a0428a6d21
Status: Downloaded newer image for ubuntu:latest
 ---> 08d22c0ceb15
Step 2/2 : RUN echo " my name is divya" >/tmp/divya
 ---> Running in 194a08c5b440
Removing intermediate container 194a08c5b440
 ---> b482871e9470
Successfully built b482871e9470
Successfully tagged image1:latest
>docker images

o/p: REPOSITORY   TAG       IMAGE ID       CREATED              SIZE
image1       latest    b482871e9470   About a minute ago   77.8MB
ubuntu       latest    08d22c0ceb15   8 days ago           77.8MB

docker ps -a
no containers

create container :

docker run -it --name cont-1 image1 /bin/bash
cd /tmp/
ll
cat divya
o/p: my name is divya
exit


Another examples:
vim Dockerfile
FROM ubuntu
WORKDIR /tmp
RUN echo "learning docker file automation" >/tmp/divya
ENV name divya
COPY file1 /tmp
ADD test.tar.gz /tmpp

cat Dockerfile
docker build -t image2 .    HERE .--- represents the current directory
build failed 
because : in docker file we copying the file1 , but we didn't crewated the file1
vim file1
thgis is my file1
cat Dockerfile
next we want test.tar.gz file for that
touch test
tar -cvf test.tar test   ----creating test to test.tar file
ll
gzip test.tar  ----creating test.tar file to test.tar.gz file
ll
NOw don't need the test file --- rm -rf test
ll

cat Dockerfile
docker build -t image2 .
o/p: Sending build context to Docker daemon  113.3MB
Step 1/6 : FROM ubuntu
 ---> 08d22c0ceb15
Step 2/6 : WORKDIR /tmp
 ---> Using cache
 ---> f9bb3dd48af1
Step 3/6 : RUN echo "learning docker file automation" >/tmp/divya
 ---> Using cache
 ---> a2170765c6e1
Step 4/6 : ENV name divya
 ---> Using cache
 ---> 246c5364a7f6
Step 5/6 : COPY file1 /tmp
 ---> 06ebfbcfda5f
Step 6/6 : ADD test.tar.gz /tmp
 ---> 586cea877bab
Successfully built 586cea877bab
Successfully tagged image2:latest

docker images
image2       latest    586cea877bab   About a minute ago   77.8MB
image1       latest    b482871e9470   27 minutes ago       77.8MB
ubuntu       latest    08d22c0ceb15   8 days ago           77.8MB

image------> Container
docker run -it --name cont-2 image2 /bin/bash
cat Dockerfile
docker start cont-2
docker attach cont-2
cat divya
echo $name
cat file1
exit


DOCKER VOLUMES:
EBS:Elastic block storage --till 30 gd extenable
like ROM
FOR EC2
what for docker ---?
In Docker volumes
container created---- volume creates
volume is dir inside the container
sharable
after declare the directory volume ------then only sharable
If container stops ----can access the volume
declare the directory volume----while crating the container
we can't ceate the volumes ---for already existing container
1 volume --- sharable to many containers
if conainter -1 volume is shared to container -2, --- then chnages made by container-2 ---changes effected to container-1 also
mapping 2 ways
container  <---------> container
Host  <-----------> Container
deleting containers--- volumes are not created

CREATING VOLUMES:
1.create Dockerfile and write

vi Dockerfile
FROM ubuntu
VOLUME ["/krishna"]
RUN touch f1

we have docker file --- changed to container through build command
docker build -t image3 .

image created --- next create to container--- through run command
docker run -it --name cont-3 image3 /bin/bash
ll
o/p: drwxr-xr-x   1 root root  66 Mar 17 00:26 etc/
-rw-r--r--   1 root root   0 Mar 17 00:25 f1
drwxr-xr-x   2 root root   6 Apr 18  2022 home/
drwxr-xr-x   2 root root   6 Mar 17 00:25 krishna/
exit
docker ps -a 

o/p: CONTAINER ID   IMAGE     COMMAND       CREATED          STATUS                      PORTS     NAMES
a9d11cbb6c7d   image3    "/bin/bash"   2 minutes ago    Exited (0) 27 seconds ago             cont-3
bed03854c602   image2    "/bin/bash"   25 minutes ago   Exited (0) 21 minutes ago             cont-2
504d3c0fc833   image1    "/bin/bash"   52 minutes ago   Exited (0) 50 minutes ago             cont-1

docker start cont-3
docker attach cont-3
cd krishna/
ll
cat>kittu
This is my volume-1
exit
docker ps -a

NOw we have cont-3 , in that cont-3 has kittu volume
Now it can be sharable to other containers

VOLUME SHARING:Automatic

docker login
username:divyatunuguntla
pwd:Prudhviraj467*
Credentials--- should dockerhub details

docker run -it --name cont-4 --privileged=true --volumes-from cont-3 image3 /bin/bash
cd krishna/
ll
cat kittu

we have cont-3 and volume is kittu ----- shared to cont-4 and having same volume of kittu
Now if we are going to do any changes in cont-4 of volume kittu --- changes will reflect in cont-3 of volume kittu

now in cont-4 ---krishna file--->    root@f3ff672954a1:/krishna# cat>krishna1
This is modified content
exit

docker ps -a
docker start cont-3
docker attach cont-3
 cd krishna/
 ll
 cat krishna1
 This is modified content
 
 if wnat to know which containers having volumes:
  docker container inspect cont-1
  
  delete the images : docker rmi <your-image-id>
  docker image prune
  
  DOCKER PORTS: Connecting jenkins with port number by using docker
  
  yum install docker -y
  docker --version
  service docker start
  service docker status
  docker images
  docker ps -a
  docker pull jenkinsci/jenkins
  docker run -it --name cont-1 jenkinsci/jenkins /bin/bash
  exit
  docker inspect jenkinsci/jenkins
  We need to assign the port number
  docker run -p 8080:8080 -p 5000:5000 jenkinsci/jenkins
  o/p: This may also be found at: /var/jenkins_home/secrets/initialAdminPassword
  copy public ip address and paste it in url:8080 --- we will get jenkins login page and paste the password
  
  Google search commands:
  
sudo yum update -y                             # To update all packages
sudo amazon-linux-extras install docker        # To install docker latest version
sudo service docker start                      # To start docker service
sudo service docker status                     # To check status of docker service. If it's running or not.
sudo systemctl enable docker                   # To ensure that docker service start after each reboot 
sudo usermod -a -G docker ec2-user             # To add ec2-user to docker group

for detailed explanation: https://www.geeksforgeeks.org/how-to-setup-jenkins-in-docker-container/


  
  Exec and Attach:
  
  Attach is used for go inside of the container
  Exec is also used for go inside of the container but creates the new process for entering the container
  ppid : parent process id ,pid: process id
  
  Expose and Public:
  
  3 ways: 1. Neither specify expose nor -p:---- that service in the container will only be accessible from inside of the container itself
  
          2. Only specifies expose : if you expose a port  -- the service in the container is not accessible from outside of docker,but from inside other docker      
             containers, this is good for inner docker container communication.    
           
          3. specify expose and -p : ---- the service in the container is accessible from anywhere,even outside of the docker
          
          If u do -p only but do not expose ---- docker does an implict expose.this is becoz if a port is oen to the public ,it is automatically open to the other      docker containers.
  
  
 DOCKER PUSH:
 
 image----container(some editings)----image----docker hub
 //// in ubuntu default we didn't get vim and default we get nano////
 
 
 docker pull ubuntu
 docker images
 docker run -it --name cont-5  ubuntu /bin/bash
 cd /tmp/
 touch d1 d2 d3 d4
 ll
 apt update -y
 apt install git -y
 apt install tree vim -y
 exit
 docker images
 wana build image from container -- will use committ command:
 Already we have an container -- cont-push and can be changing to image --- ubuntu-1
 
 docker commit cont-push ubuntu-1
 docker images
 
 docker hub pushing: 
 docker login : divyatunuguntla
 Prudhviraj467*
 
 ////IN git to github , if we want push the code , we will do commit, in the same way we need to do tag in docker////
 
 docker tag imagename reponame
 docker tag ubuntu-1 divyatunuguntla/chocolatefile
 docker images
 docker push divyatunuguntla/chocolatefile
 
 OTHER COMMANDS:
 
 docker images
 docker ps 
 docker ps -a
 To stop all the containers which are in start mode: docker stop $(docker ps -a -q)
 To delete all stopped containers: docker rm $(docker ps -a -q)
 to delete all images : docker rmi -f $(docker images -q)
 
 DOCKER SWARM:
 Container Management
 cluster is collection of nodes 
 Managing of clusters
 Swarm worker and Swarm Manager
 
 
 Docker engine creates --- docker swarm manager ----creates swarm worker nodes

Docker Swarm Components:

Service: Represents a part of the feature of an application
Task: A single part of work
Manager: This manages the work among the different nodes.
Worker : Which works for a specific purpose of the service

INFRASTRUCTURE OF THE SWARM:

1. CREATE 3 NODES 1---MANAGER , 2 ---WORKER NODES.

sudo -i
sudo yum update -y
docker --version
service docker start
service docker status
docker swarm init --advertise-addr 18.217.78.75   Here: master docker public ip address
o/p: Swarm initialized: current node (hitqijfsti08sqqr2flyughdk) is now a manager.

To add a worker to this swarm, run the following command:

    docker swarm join --token SWMTKN-1-2jrhrpvnn2d5u4pvjz1l096quqmoz2sp4vfmz4qkorzpiblo54-2qpll8ffcqvqzai9doppki2wd 18.217.78.75:2377

To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions. 


// If we have error on connecting the same nodde as manager --leave the swarm

docker swarm leave --force
Do same process again : docker swarm init --advertise-addr 18.217.78.75   Here: master docker public ip address


wana know the ports running on EC2 : netstat -tulpn | grep LISTEN

docker swarm join --token SWMTKN-1-61gnpq745hvigyc3zj2zc12oukr3e2a1ug846uahi6n6ok3ett-161vg26o9jvlngmvvqbld8mnu 18.217.78.75:2377

want to know how many nodes are connected to manager

   > docker node ls 

 
 o/p: ID                            HOSTNAME                                      STATUS    AVAILABILITY   MANAGER STATUS   ENGINE VERSION
turdjsbifukpppzg4eb4n1zw6     ip-172-31-13-56.us-east-2.compute.internal    Ready     Active                          20.10.17
w0thfgtynwy60lmwfhz87i1j1     ip-172-31-39-219.us-east-2.compute.internal   Ready     Active                          20.10.17
z2ps7x2j0hdj84du4cew4ta3a *   ip-172-31-43-54.us-east-2.compute.internal    Ready     Active         Leader           20.10.17

> details of manager /nodes: docker info

Permanently delete the node:

master node >docker node rm node -id 

docker swarm leave

to delete permanently docker node: docker node rm dockernode-id

To delete the manager forcefully:

docker swarm leave --force

docker swarm join-token worker  ---------------> it gives the worker token
docker swarm join-token manager -------------------> it give the manager token



CREATING A SERVICE ON SWARM:


Service: service is nothing but a container
We have replicas , if one service is down ,other will work as backup

create a service : > docker service

create a docker service: docker service create --name mtickets --replicas 3 --publish 80:80 httpd

Here: mtickets is the servicename , replicas : h/w many nodes ,httpd---image name

docker service ls

o/p: ID             NAME       MODE         REPLICAS   IMAGE          PORTS
lu3p5wy5u4hn   mtickets   replicated   3/3        httpd:latest   *:80->80/tcp

for service creation automatically container creates: docker ps -a

docker ps  ---- container is up , normally container is down but when service is created and container automatically creates as up.

To remove all services:

docker rm -f servicename  or /

docker rm -f containerID

Wnana see the service in physically : copy public IP and paste in browser:80

inspect the container: docker inspect containerID
inspect service: docker service inspect --pretty servicename -----o/p: is json formate
docker service inspect servicename -----o/p: is YAML formate



DOCKER STACK:

It is used to launch whole software together
you will write all the services and launch them together

docker stack deploy -c demo.yml demostack

demo.yml---name of the file , demostack ---name of stack
vim demo.yml
docker compose install search in google chrome ---- in this page we will get the installation commands :https://docs.docker.com/compose/install/other/

To download and install Compose standalone, run
curl -SL https://github.com/docker/compose/releases/download/v2.16.0/docker-compose-linux-x86_64 -o /usr/local/bin/docker-compose ---------docker compose installation
chmod +x /usr/local/bin/docker-compose  ------------------giving permissions
ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose ----------creating link for compose
docker compose --version
rm -rf *
vim docker-compose.yml
version: '3'
services:
   webapp1:
     image: nginx
     ports:
       - "8000:80"  

8000 ------is going to map ur container ,  80: ----port tcp

docker-compose up ------------------all the appications we wana run can be placed in yml file and that file is going to run by using the command up.

copy public ip address and paste in browser with :8000 and we will get the ngix page

///// If wana get 2 ngix in the browser:

vim docker-compose.yml
version: '3'
services:
   webapp1:
     image: nginx
     ports:
       - "8000:80"
   webapp2:
     image: nginx
     ports:
     ports:
       - "8001:80" 
 docker-compose up
 same copy public ip :8001 ----we will see the ngix page
 docker images
 we will see the ngix --- automatically creates the image
 
 /// if we want any commands related to docker compose ----------docker-compose --help
       
       
docker compose detailed explanation: https://docs.docker.com/compose/gettingstarted/

wana stop your services: docker-compose stop

You can bring everything down, removing the containers entirely, with the down command. Pass --volumes to also remove the data volume used by the Redis container:
docker compose down --volumes



DOCKER PORTS:

installing jenkins fron docker hub to docker :

docker pull jenkinsci/jenkins -----here : this command available in docker hub directly as an image with all the dependencies in our local docker

docker run -it --name cont-9 jenkinsci/jenkins /bin/bash
docker run -p 8080:8080 -p 5000:5000 jenkinsci/jenkins

01453a65026044109d0f08364694ceaf

This may also be found at: /var/jenkins_home/secrets/initialAdminPassword

copy public ip and paste in browser with Public ip of docker master:8080 ---we will get jenkins page to login and paste the admin password here

want to come to root user ---control+c
 
 
KUBERNETES:K8S ---CONTAINER MANAGEMENT TOOL

Container Management
Automates - Container deployment,container scaling and Load Balancing
It schedules,runs and manages isolated containers which are running on virtual/physical/cloud machines
It is supported by all the cloud providers
Google introduces K8s as an open source
k8s uses Go-lang
docker also Go-lang
Cloud Native Computing Foundation---donated by Google

 GKS:Google kubernetes services ----best
 AKS:Azure Kubernetes services
 EKS: Elastic Kubernetes Services
 
 Tools: Mini-kude, Kube-adm ,Kube-ctl ---command line
 
 CONTAINER SCALEUP PROBLEMS:
 Complexity
 Containers cannot communicate each other
 Auto scalling and Load balancing was not possible
 Containers had to be managed carefully
 
 Auto scalling ---Automatically elastic of the containers
 Load Balancing -----Managing containers
 
 
 K8S Features:
 
 Orchestration: clustering of any no of containers running on different networks
 Auto scalling vertical --existing nodes manages --most preferable  and horizontal ----new nodes creates 
 Auto healing
 Load Balancing
 Platform independent --cloud/virtual/physical
 Fault tolerance(Node/pod Failure)
 Roll back(Going back to previous version)
 Health Monitoring of containers --If 1 container fails it will create another container
 Batch Execution ---Onetime,sequential,parallel
 Scripts in k8s is called manifest,which is in form of json or YAML
 
 
 PARAMETERS:                                     DOCKER SWARM:                                                     KUBERNETES:
 
 1. Scaling                                      No Auto Scaling                                                    Auto-Scaling
 2. Load Balancing                               Does Auto-Load Balancing                                       Manually configure your load balancing settings
 3. Storage Volume sharing                       shares storage
 
  1  useradd ansible
    2  passwd ansible
    3  visudo
    4  vim /etc/ssh/sshd_config
    5  sudo systemctl restart sshd
    6  sudo systemctl status  sshd
    7  su - ansible
    8  git --version
    9  tree --version
   10  su - ansible
   11  sudo yum remove git -y
   12  git --version
   13  su - ansible
   14  sudo yum update-y
   15  docker --version
   16  docker images
   17  docker search jenkins
   18  docker images
   19  docker ps
   20  docker ps -a
   21  cat /etc/os-release
   22  docket run -it --name divya ubuntu /bin/bash
   23  docket run -it --name divya1 ubuntu /bin/bash
   24  docker run -it --name divya1 ubuntu /bin/bash
   25  docker ps -a
   26  docker run -it --name divya2  ubuntu touch f1 
   27  docker ps -a
   28  docker start divya1
   29  docker ps -a
   30  docker ps
   31  docker attach divya1
   32  docker ps -s
   33  docker ps -a
   34  docker attach quizzical_jemison
   35  yum install docker -y
   36  docker --version
   37  docker version
   38  systemctl restart docker.service
   39  systemctl status  docker.service
   40  docker version
   41  ll
   42  history
   43  docker info
   44  docker images
   45  docker pull ubuntu
   46  docker images
   47  docker run redis
   48  docker ps -a
   49  docker stop ps 
   50  docker ps -a
   51  docker ps
   52  docker stop redis
   53  docker ps 
   54  docker ps -a
   55  docker rm divya2
   56  docker ps -a
   57  docker rm divya1
   58  docker ps -a
   59  docker stop redis
   60  docker stop quizzical_jemison
   61  docker ps -a
   62  docker rm thirsty_jang
   63  docker rm gallant_ptolemy
   64  quizzical_jemison
   65  docker ps -a
   66  docker rm quizzical_jemison
   67  docker ps -a
   68  docker ps
   69  docker images
   70  docker run -it --name divya ubuntu /bin/bash
   71  docker diff divya
   72  docker images
   73  docker ps
   74  docker ps -a
   75  docker commit divya ubuntu
   76  docker images
   77  docker commit divya ubuntu1
   78  docker images
   79  docker rm ubuntu
   80  docker ps -a
   81  docker images
   82  docker run -it --name divya1 ubuntu1
   83  docker images
   84  docker commit divya1 ubuntu1
   85  docker images
   86  docker run -it --name divya2 ubuntu1
   87  history
   88  docker images
   89  docker ps -a
   90  docker image rm ubuntu1
   91  docker rm ubuntu1
   92  docker image rm ubuntu1
   93  docker image rm [ubuntu1]
   94  docker rm 60e2f14dde57
   95  docker images
   96  sudo yum update -y
   97  yum install docker -y
   98  docker --version
   99  docker version
  100  systemctl restart docker.service
  101  systemctl status  docker.service
  102  docker version
  103  docker images
  104  docker ps -a
  105  docker images
  106  docker ps
  107  docker ps -a
  108  history
  109  docker pull alpine
  110  docker ps -a
  111  docker run alpine
  112  docker ps -a
  113  docker search jenkins
  114  docker images
  115  docker ps -a
  116  docker run -t
  117  docker run -it ubuntu
  118  sudo yum update -y
  119  docker swarm init --advertise-addr 18.217.78.75    
  120  docker --version
  121  service docker start
  122  service docker status
  123  docker swarm init --advertise-addr 18.217.78.75    
  124  service docker start
  125  service docker status
  126  docker swarm init --advertise-addr 18.217.78.75    
  127  docker swarm leave
  128  docker swarm init --advertise-addr 18.217.78.75    
  129  docker --version
  130  docker swarm init --advertise-addr 18.217.78.75    
  131  docker --version
  132  docker version
  133  service docker start
  134  service docker status
  135  docker swarm init --advertise-addr 18.217.78.75
  136  docker info
  137  docker swarm leave --force
  138  docker swarm init --advertise-addr 18.217.78.75   Here: master docker public ip address
  139  docker swarm init --advertise-addr 18.217.78.75
  140  netstat -tulpn | grep LISTEN
  141  ufw allow 22/tcp && ufw allow 53/tcp && ufw allow 2377/tcp && ufw allow 7946/tcp && ufw allow 7946/udp && ufw allow 4789/udp && ufw reload && ufw enable && systemctl restart docker
  142  docker info
  143  service docker restart
  144  service docker status
  145  docker swarm leave --f
  146  docker swarm leave --force
  147  docker swarm init --listen-addr <18.217.78.75:2377>
  148  docker swarm init --advertise-addr 18.217.78.75
  149  docker node ls
  150  docker info
  151  docker node ls
  152  docker service create --name mtickets --replicas 3 --publish 80:80 httpd
  153  docker service ls
  154  docker service
  155  docker service ls
  156  docker ps -a
  157  docker ps
  158  docker service ls
  159  docker ps 
  160  docker inspect 1347cb9e14aa
  161  docker service ls
  162  docker service inspect --pretty mtickets
  163  docker stack deploy -c demo.yml demostack
  164  sudo yum update -y
  165  docker images
  166  docker yum install -y
  167  docker yum install - y
  168  sudo yum install docker - y
  169  yum install docker - y
  170  docker images
  171  docker --version
  172  docker version
  173  service docker start
  174  service docker status
  175  docker images
  176  docker rm images *
  177  docker rm -rf images
  178  docker rmi -f $(docker images -q)
  179  docker images
  180  docker ps -a
  181  docker rm divya
  182  docker rm divya1
  183  docker rm divya2
  184  docker rm mtickets.1.p4vcb63p2qszst9m1wsca7kmj
  185  docker stop mtickets.1.p4vcb63p2qszst9m1wsca7kmj
  186  docker stop mtickets.3.pzssn5q26006ffhkdx4gbp18l
  187  docker stop mtickets.2.yad45k35u8sbvjm672o7j394c
  188  docker stop mtickets.2.j45q4n4awndhns20he0mls27q
  189  docker rm mtickets.2.j45q4n4awndhns20he0mls27q
  190  docker rm mtickets.2.yad45k35u8sbvjm672o7j394c
  191  docker rm mtickets.3.pzssn5q26006ffhkdx4gbp18l
  192  docker rm mtickets.1.p4vcb63p2qszst9m1wsca7kmj
  193  docker ps -a
  194  docker ps
  195  docker stop mtickets.2.kfbvmomhfjshgyngt3eiis952
  196  docker ps
  197  docker stop mtickets.3.pzx4eszuhg4nzx2956cr2jzae
  198  docker stop mtickets.1.r1ewxu3pjgwlpkcd8q09p90g1
  199  docker ps
  200  docker ps -a
  201  docker rm mtickets.2.rabv9c0gcofg6lb6cijbq4rsg
  202  docker pull jenkinsci/jenkins
  203  docker run -t --name cont-9 jenkinsci/jenkins
  204  service docker start
  205  service docker status
  206  docker run -t --name cont-9 jenkinsci/jenkis /bin/bash
  207  docker login
  208  docker run -t --name cont-9 jenkinsci/jenkis /bin/bash
  209  docker run -t --name cont-8 jenkisci/jenkins /bin/bash
  210  docker run -t --name cont-8 jenkisci/jenkins/bin/bash
  211  docker run -t --name cont-1 jenkisci/jenkins/bin/bash
  212  docker inspect jenkinsci/jenkins
  213  docker run -p 8080:8080 -p 5000:5000 jenkinsci/jenkins
  214  docker ps -a
  215  service docker start
  216  service docker status
  217  docker images
  218  docker run redis
  219  docker ps -a
  220  docker images
  221  docker run -it --name cont-2 ubuntu /bin/bash
  222  docker images
  223  docker commit cont-2 ubuntu-1
  224  docker images
  225  docker login
  226  docker images 
  227  docker tag ubuntu-1 divyatunuguntla
  228  /
  229  docker tag ubuntu-1 divyatunuguntla/biscuitfactory
  230  docker images
  231  docker push divyatunuguntla/biscuitfactory
  232  docker images
  233  docker ps -a
  234  docker stop $(docker ps -a -q)
  235  docker rm $(docker ps -a -q)
  236  docker ps -a
  237  docker stop $(docker ps -a -q)
  238  docker rm $(docker ps -a -q)
  239  docker stop $(docker ps -a -q)
  240  docker rmi -f $(docker images -q)
  241  docker images
  242  docker ps
  243  docker stop mtickets.1.im3hmow322pumk1aom414f7zr
  244  docker ps
  245  docker stop mtickets.2.v7fx0qugkmibal2cbl0bl5ry7
  246  docker stop mtickets.3.lalz7kwu2ew58vps504ljw9uf
  247  docker ps
  248  docker stop mtickets.2.yatqpyusz61wmjqrfy0le8iu6
  249  docker stop mtickets.1.nnq0jcxct5p14sniuuhfnzr50
  250  docker ps
  251  docker ps -a
  252  docker swarm init --advertise-addr 3.22.236.175    
  253  docker swarm leave --force
  254  docker swarm init --advertise-addr 3.22.236.175
  255  docker node ls
  256  docker info
  257  docker service create -name payments -replicas 3 -publish 80:80 httpd
  258  docker service create --name payments --replicas 3 --publish 80:80 httpd
  259  docker service ls
  260  docker ps -a
  261  docker ps
  262  docker rm -f payments
  263  docker rm -f a1c0afcbed72
  264  docker ps
  265  docker inspect a1c0afcbed72
  266  docker service ls
  267  docker service inspect --pretty payments
  268  docker service inspect  payments
  269  docker stack deploy -c demo.yml demostack
  270  vim demo.yml
  271  curl -SL https://github.com/docker/compose/releases/download/v2.16.0/docker-compose-linux-x86_64 -o /usr/local/bin/docker-compose
  272  chmod +x /usr/local/bin/docker-compose
  273  ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose
  274  docker compose --version
  275  ll
  276  rm -rf *
  277  vim docker-compose.yml
  278  docker-compose up
  279  vim docker-compose.yml
  280  docker-compose up
  281  docker images
  282  docker ps
  283  docker-compose --help
  284  vim docker-compose.yml
  285  docker compose up
  286  docker-compose up
  287  vim dockerfile
  288  docker-compose up
  289  vim requirements.txt
  290  docker-compose up
  291  vim app.py
  292  docker-compose up
  293  mkdir composetest
  294  cd composetest
  295  copy app.py
  296  cd ../
  297  ll
  298  rm -rf *
  299  ll
  300  mkdir composetest
  301  cd composetest
  302  vim app.py
  303  vim requirements.txt
  304  vim Dockerfile
  305  vim docker-compose.yml
  306  docker compose up
  307  docker-compose up
  308  cd ../
  309  docker-compose ps
  310  docker-compose down --volumes
  311  docker compose down --volumes
  312  ll
  313  rm -rf *
  314  ll
  315  yum install git -y
  316  cat /etc/passwd/
  317  cat /etc/passwd
  318  curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
  319  ll
  320  chmode +x minikube
  321  chmod +x minikube
  322  sudo mv minikube /usr/local/bin/
  323  ls usr/local/bin
  324  ls /usr/local/bin
  325  minikube version
  326  minikube --version
  327  minikube version
  328  minikube -version
  329  minikube --version
  330  sudo minikube start --vm-driver=none
  331  minikube start
  332  choco install curl
  333  curl http://google.com 
  334  minikube start
  335  $ curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
  336  $ minikube status
  337  curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-darwin-amd64
  338  sudo install minikube-darwin-amd64 /usr/local/bin/minikube
  339  minikube start
  340  sudo minikube start --vm-driver=none
  341  ls /usr/local/bin/
  342  cd /minikube
  343  cat minikube
  344  minikube start --driver=virtualbox
  345  Run minikube start --alsologtostderr -v=7 
  346  minikube start --driver=docker
  347  curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/darwin/amd64/kubectl
  348  ll
  349  chmod 777 kubectl
  350  mv ./kubectl /usr/local/bin/kubectl
  351  ls /usr/local/bin/
  352  rm -rf docker-compose
  353  ls /usr/local/bin/
  354  kubectl --version
  355  kubectl version
  356  $(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)
  357  curl -LO https://storage.googleapis.com/kubernetes-release/release/v1.7.0/bin/darwin/amd64/kubectl
  358  chmod +x ./kubectl
  359  sudo mv ./kubectl /usr/local/bin/kubectl
  360  ls /usr/local/bin/
  361  history
  362  kubectl version
  363  sudo apt get install docker -y
  364  yum install docker -y
  365  systemctl docker start
  366  docker version
  367  service docker restart
  368  service docker status
  369  sudo usermod -aG docker $USER && newgrp docker
  370  sudo minikube start --vm-driver=none
  371   minikube start --vm-driver=none
  372  sudo yum install conntrack -y
  373   minikube start --vm-driver=none
  374  sudo minikube start --vm-driver=none
  375  minikube status
  376  kubectl cluster info
  377  kubectl cluster-info dump
  378  kubectl get events
  379  kubectl config view
  380  kubectl run hello -minikube --image =grc.io/google_containers/echoserver:1.4--port=8080
  381  kubectl get pods
  382  kubectl create deployment hello-node--image=k8s.gcr.io/echoserver:1.4
  383  history
  
 NAGIOS: 
  
  384  sudo yum instal httpd php -y
  385  sudo yum install httpd php -y
  386  sudo yum install gcc glibc glibc-common -y
  387  sudo yum install gd gd-devel -y
  388  sudo adduser -m nagios
  389  history
  390  sudo passwd nagios
  391  sudo grpadd nagcmd
  392  sudo groupadd nagcmd
  393  sudo usermod -a -G nagcmd nagios
  394  sudo usermod -a -G nagcmd apache
  395  mkdir ~/downloads
  396  cd ~/downloads
  397  wget http://prdownloads.sourceforge.net/sourceforge/nagios/nagios-4.0.8.tar.gz
  398  wget http://nagios-plugins.org/download/nagios-plugins-2.0.3.tar.gz
  399   tar zxvf nagios-4.0.8.tar.gz
  400  ll
  401  cd nagios-4.0.8/
  402  ./configure --with-command-group=nagcmd
  403  make all
  404  sudo make install
  405   sudo make install-init 
  406  sudo make install-config
  407  sudo make install-commandmode
  408  sudo vim /usr/local/nagios/etc/objects/contacts.cfg
  409  sudo make install-webconf
  410  sudo make install-webconfig
  411   make install-webconfig
  412  cd  nagios-4.0.8
  413  history
  414  cd ~/downloads
  415  cd nagios-4.0.8/
  416  make install-webconf
  417   sudo htpasswd -c /usr/local/nagios/etc/htpasswd.users nagiosadmin
  418  sudo service httpd restart
  419  sudo service httpd status
  420  cd ~/downloads
  421  tar zxvf nagios-plugins-2.0.3.tar.gz
  422  cd ~/downloads 
  423   tar zxvf nagios-plugins-2.0.3.tar.gz
  424  cd nagios-plugins-2.0.3
  425  ./configure --with-nagios-user=nagios --with-nagios-group=nagios
  426  sudo make install
  427  sudo chkconfig --add nagios
  428  sudo chkconfig nagios on
  429  sudo /usr/local/nagios/bin/nagios -v /usr/local/nagios/etc/nagios.cfg
  430  sudo service nagios start
  431  sudo service nagios sshd
  432  sudo service sshd stsrt
  433  sudo service sshd start
  434  sudo service sshd status
  435  history
 
 



 





 

 
 
 



 
   
   

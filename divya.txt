kubernetes : Containerasation Management ,vertical & horizontal scaling , command line & GUI interface,
Architecture 
How to Deploy : 2 vm's---1 master and 1 slave
master should have atleast 2 core cpu's & 4GB RAM
Nodes  should have atleast 1 core CPU & 4GB RAM ,ubuntu O.S
On Master 
ifconfig--- finding IP address of the master machine
sudo kubeadm init--pod-network-cidr=<> --apiserver-advertise-address=<ip-address-of-master>
//For starting a Calico CNI : 192.168.0.0/16 or For starting a plannel CNI : 10.244.0.0/16
// copy the kubeadm token generated on the terminal -----helpful for joining the nodes or connecting slave to the master

U will find the 3 commands on the terminal like to start using your cluster,you need to run the following as aregular user---copy that commands  and paste it in the same page of the master

// For creating a POD based on Calico
//want to know the nodes
kubectl get nodes
//Want to know the PODS
kubectl get pods --all-namespaces -o wide
//For Creating the dashboard first - bring this up before starting or joining the Nodes
// To enable Proxy and continues with new terminal window
kubectl proxy
copy the ip address and paste it website like localhost:8001
//For dashboard create the service account
kubectl create serviceaccount dashboard -n default
//Role Binding
kubectl create clusterrolebinding dashboard-admin -n default \
 --clusterrole=cluster-admin \
 --serviceaccount=default:dashboard
 //To get the secret key to be pasted into the dashboard token pwd,copy the outcoming secrete key
 we will get the token generated in master terminal and paste in the localhost:8001------- and then login is accessible to kubernetes dashboards
 open node terminal---master IP paste in the node terminal
 IN Dashboard---we can see master and nodes
 //How to deploy the apps  by using the GUI in dashboard---Create an app---app name--nginx(container image)--no of pods(Containers)--1/2 ---External--port no : 82 , 80--DEPLOY---click on 1 pod--copy the port number and paste in the localhost we will see the page
//HOw to deploy the apps through CLI on master terminal  
//1st create a deployment----> kubectl create deployment nginx --image=nginx
//Verify the deployment --->kubectl get deployments
//more details about the deployment---->kubectl describe deployment nginx
//Create service on the nodes-----> kubectl create service nodeport nginx --tcp=80:80
//To check which deployment is running on which node----> kubectl get svc
//To delete deployment ------> kubectl delete deployment <name>
//Deployment via yaml code 
//write the yaml code in nodepad and save as file in your system
ls
gedit deployment.yaml----file name
//Create a Deployment using Yaml ---> kubectl create -f deployment.yaml

ANSIBLE : Managing multiple servers via configuration management, Auto scalling up or down , Rolling back
Ansible is the configuration management tool like puppet,chef,saltstack
simple to install and setup,NO need of any agent/client software to manage the nodes,capabilites to model complex IT workflows and orchestrate your entire IT infrastructure,Extensible with modules written in any programming language
Ansible Tower : it is web based interface to amnaging enterprise levels




ip addr show --- checking Ip address
hostname -i 
ifconfig
ping ----------checking the server response
ping 8.8.8.8
ping google.com
control+z --- stopping the command
who is domain----getting data about domain
dig domain ----forward lookup
dig -x host ---- reverse lookup
host google.com
active ports ---netstack -pnltu
wget filename ---download the file from online source
hostname -i -------diplays local IP address
changing from file to tar file ----tar -cvf filename.tar filename

here --- filename.tar ----destination
   filename ------source
   
   UNTAR --- changing form tar to normal file
   first do Gzip and the untar
   gzip filename.tar.gz filename.tar
   tar -zxvf filename.tar.gz
   fdisk -l -----listing the disk total space
   free -m ----- view the free space
   df -- mount paoints --- in kbs
   df -Th ---- mount points --- in mbs
   df -i -------i nodes ( the total data stored in the disk is I nodes)
   du -sh ----view the memory usage in kilobytes
   moving from folder to root --- cd/root/
   moving to folder ----cd dir1/  or cd~   or cd
   coming back -- cd ..
   cd ../..
   cd ..\..
   cd c/d/
   cd -    -----going to back to the same path
   
   yum install tree
   tree
   EX: directories : a/b/c/d/e
   come to c dir : cd a/b/c/
   come to a dir : cd ../..
   again back to c dir : cd -
   
   GREP Commands: Global Regular Expression Print --- searching purpose in the files
   grep divya file1  or grep -i divya file1  or cat file1| grep devops  ----o/p: searches the divya word in the file1
   grep -v divya file1 ----o/p:  except that word ,all lines shows in the file
   cat file1| grep devops ----o/p: that devops word lines in the file are excuted
   
   SED Commands : STREAM EDitor
   sed '=' file1 -----o/p: excutes the lines with line numbers i separate lines
   sed -n '3,6p' file1 ----o/p: excutes 3 to 6 lines in the file1
   echo Hi | sed 's/Hi/Hello/' ----chnaging word Hi to Hello 
   sed '3c\kittu' file1 --- To chnage the 3rd line in the  file
   
   Linux Dirctory system:
   FHS : fully hirearchy system
   etc : it contains all the host specific system configuration files
   proc : it is used to see all the processing related files (hardware details)
   home : users home directory
   bin: it stores all the binary files and also it stores the commands that has been excuted by the user
   adduser name
   chnaging password: passwd username
   enter password
   MOving from Root user to divvi user : visudo
   shift+g
   Allow root to run any command anywhere 
   yyp
   divvi   all =all   nopasswd:all
   shift: wq
   su - divvi --- chnaging from root to divvi user
   adding 1 user to another user --- sudo useradd anu
   paasword anu enter
    cloud --- directory ----1.aws dir---- 3files (aws1,aws2,aws3)rwx --aws 1 user and 1 group
                            2.Azure dir ---3 files (az1,az2,az3) rw ---azure 1 user ki owner user  and group ki root owner
                            3. GCP dir --- 3 files (gcp 1,gcp2,gcp3) only write permission -- gcp user ---root ,group owner is GCP
                            
                            
     mkdir clouds
     cd clouds/
     ll
     mkdir aws azure gcp
     cd aws/
     touch aws{1..3}
     ll
     chmod 777 *
     ll
     useradd aws
     chown aws:aws *
     ll
     cd
     create the links 
     ln -s clouds/aws/aws1 aws1
     ll
     ln -s clouds/aws/aws2 aws2
     ll
     ln -s clouds/aws/aws3 aws3
     
     Forget password : ???
     useradd meena
     passwd meena
     123456
     123456
     forget password then
     passwd meena
     again changing the new password
              
   
   
   Jennkins _ Master slave  :                   starting of the master -if connection not happening ---sudo amazon-linux-extras install epel -y
   
   Running from: /usr/share/java/jenkins.war
   cat /etc/passwd
   usernad passwd : passwd jenkins
   
   In SLAVE :
   usr and pwd same steps as in master
   master >  su - jenkins   ----switching to jenkins user
    ssh-keygen --- key gen for connecting nodes
    Generating public/private rsa key pair.
Enter file in which to save the key (/var/lib/jenkins/.ssh/id_rsa):
enter
enter
enter ---public and private keys generates
ls /var/lib/jenkins/.ssh/   ----keys are in this path   id_rsa  id_rsa.pub
ssh-copy-id jenkins@localhost
yes  --- o/p : Number of key(s) added: 1
ssh 'jenkins@localhost'  -- connecting to local host
hostname -i
u will get private ip ---- means master jenkins machine is connected to local machine
exit -----o/p:logout
Connection to localhost closed.
master>ssh-copy-id jenkins@52.14.201.222    ---- connecting slave 1 by using pubic ip slave 1
yes
password of slave 1 password
ssh 'jenkins@slave1 public ip address'
then we will see the slave 1 private ip address means in master slave ip address can be seen so connectin is done with the master and slave

slave2 : useradd jenkins
passwd jenkins
saidivya
visudo
yyp -- copy paste root user
jenkins all nopasswd:all
vim /etc/ssh/sshd_config   --- password authentication yes
systemctl restart sshd
systemctl status sshd
IN master > -bash-4.2$   ssh-copy-id jenkins@slave2 public ip
yes
slave2 password
copy command
ssh 'jenkins:slave2 public ip'
will see the private ip address of slave2

How many slave nodes are connected to master----jnkins GUI -- manage jenkins---manage nodes and clouds---

IN slave to master connection:
su - jenkins
ssh-keygen
enter
enter
enter
jenkins slave>ssh-copy-id jenkins@localhost
key generated
ssh 'jenkins@localhost'
exit
>ssh-copy-id jenkins@master ip address
yes
enter
password : master pwd
ssh jenkins@master public ip address
hostname -i
u will see the master private ip address





AWS console: https://aws.amazon.com/marketplace/partners/management-tour
codingrad : https://learn.codingrad.com/student-login/  ----notes
https://learn.codingrad.com/devops-april-2022/    ----videos
https://hub.docker.com/choose-plan?ref=signup --- username :divyatunuguntla,saidivya550@gmail.com,pwd:Prudhviraj467*




Docker:


cat /etc/os-release
list the containers in ec2 --- docker ps -a   ---- it shows runinng and stopped containers also
create container with new name ---- docker run -it --name divya ubuntu  ------------------------divya container is created with ubuntu image
docker run -it --name divya ubuntu /bin/bash  ---- another way to create container
docker run -it --name divya1 ubuntu /bin/bash
 docker run -it --name divya2  ubuntu touch f1 
 If we wana add any files  and going inside of the container , -- we need to start the container -----> docker start divya1
 docker ps -a
 docker ps
 docker attach divya1 ---- going inside of container divya1
 docker stop divya2 -- stps the container
 docker rm divya1 ---- removes the container
 
 BUILD AN CONTAINER FROM IMAGE:
 docker images
 ex: we have ubuntu image then create a container from image
 docker run -it --name divya ubuntu /bin/bash
 wana create tem file in divya container ---  cd /tmp/
 cat>divya
 
 hi all hhkjpl ----control+d
 exit
 docker diff divya --o/p: C /root
A /root/.bash_history
C /tmp
A /tmp/divya
 Here: a -- append ,c-change ,d: deletion
 
 Now image1 -----> container (divya file ,some edits happened) ------>Image2 builded ---- then in this image2 --we will see the divya file.
 
 may11 th video:
 
 docker commit divya ubuntu1
 docker images
 docker run -it --name divya ubuntu /bin/bash
     docker diff divya
    docker images
    docker ps
    docker ps -a
    docker commit divya ubuntu
    docker images
    docker commit divya ubuntu1
   docker images
    docker rm ubuntu
    docker ps -a
    docker images
   docker run -it --name divya1 ubuntu1
   docker images
    docker commit divya1 ubuntu1
    docker images
   docker run -it --name divya2 ubuntu1
   
   DOCKER FILE:
   
   image --> container (file --adding,commiting)cd f1---->image
   All this is manual process ,we need to do Automate the process through docker file
   
   text file
   automation of docker image creation
   d is capital in docker file
   starts components also be capital letter
   
 DOCKER FILE COMPONENTS: FROM,RUN,COPY,ADD,EXPOSE,WORKDIR,CMD,ENTRYPOINT,ENV,ARG ......
 COPY : COPYIES THE LOCAL FILES
 ADD: EXTRAS the files from internet and docker
 
 
 
 
 DOCKER FILE CREATION:
 
 CREATE A FILE ----docker file
 IN docker File -----Add instructions
 Build docker file-----to create the docker image
 Run image----to create a container
 
 sudo -i
 sudo yum update -y
 sudo yum install docker -y
 docker --version
 docker version 
 will see only client and host
 systemctl restart docker.service
 systemctl status docker.service
 docker version
 will see the client and server data
 docker images
 docker ps
 docker ps -a
 vim Dockerfile
 FROM ubuntu
 RUN echo " my name is divya" >/tmp/divya
  cat Dockerfile
  
  Creating an image:
  docker build -t image1 .      ------. represents current directory
  o/p:
  Sending build context to Docker daemon  113.3MB
Step 1/2 : FROM ubuntu
latest: Pulling from library/ubuntu
2ab09b027e7f: Pull complete 
Digest: sha256:67211c14fa74f070d27cc59d69a7fa9aeff8e28ea118ef3babc295a0428a6d21
Status: Downloaded newer image for ubuntu:latest
 ---> 08d22c0ceb15
Step 2/2 : RUN echo " my name is divya" >/tmp/divya
 ---> Running in 194a08c5b440
Removing intermediate container 194a08c5b440
 ---> b482871e9470
Successfully built b482871e9470
Successfully tagged image1:latest
>docker images

o/p: REPOSITORY   TAG       IMAGE ID       CREATED              SIZE
image1       latest    b482871e9470   About a minute ago   77.8MB
ubuntu       latest    08d22c0ceb15   8 days ago           77.8MB

docker ps -a
no containers

create container :

docker run -it --name cont-1 image1 /bin/bash
cd /tmp/
ll
cat divya
o/p: my name is divya
exit


Another examples:
vim Dockerfile
FROM ubuntu
WORKDIR /tmp
RUN echo "learning docker file automation" >/tmp/divya
ENV name divya
COPY file1 /tmp
ADD test.tar.gz /tmpp

cat Dockerfile
docker build -t image2 .    HERE .--- represents the current directory
build failed 
because : in docker file we copying the file1 , but we didn't crewated the file1
vim file1
thgis is my file1
cat Dockerfile
next we want test.tar.gz file for that
touch test
tar -cvf test.tar test   ----creating test to test.tar file
ll
gzip test.tar  ----creating test.tar file to test.tar.gz file
ll
NOw don't need the test file --- rm -rf test
ll

cat Dockerfile
docker build -t image2 .
o/p: Sending build context to Docker daemon  113.3MB
Step 1/6 : FROM ubuntu
 ---> 08d22c0ceb15
Step 2/6 : WORKDIR /tmp
 ---> Using cache
 ---> f9bb3dd48af1
Step 3/6 : RUN echo "learning docker file automation" >/tmp/divya
 ---> Using cache
 ---> a2170765c6e1
Step 4/6 : ENV name divya
 ---> Using cache
 ---> 246c5364a7f6
Step 5/6 : COPY file1 /tmp
 ---> 06ebfbcfda5f
Step 6/6 : ADD test.tar.gz /tmp
 ---> 586cea877bab
Successfully built 586cea877bab
Successfully tagged image2:latest

docker images
image2       latest    586cea877bab   About a minute ago   77.8MB
image1       latest    b482871e9470   27 minutes ago       77.8MB
ubuntu       latest    08d22c0ceb15   8 days ago           77.8MB

image------> Container
docker run -it --name cont-2 image2 /bin/bash
cat Dockerfile
docker start cont-2
docker attach cont-2
cat divya
echo $name
cat file1
exit


DOCKER VOLUMES:
EBS:Elastic block storage --till 30 gd extenable
like ROM
FOR EC2
what for docker ---?
In Docker volumes
container created---- volume creates
volume is dir inside the container
sharable
after declare the directory volume ------then only sharable
If container stops ----can access the volume
declare the directory volume----while crating the container
we can't ceate the volumes ---for already existing container
1 volume --- sharable to many containers
if conainter -1 volume is shared to container -2, --- then chnages made by container-2 ---changes effected to container-1 also
mapping 2 ways
container  <---------> container
Host  <-----------> Container
deleting containers--- volumes are not created

CREATING VOLUMES:
1.create Dockerfile and write

vi Dockerfile
FROM ubuntu
VOLUME ["/krishna"]
RUN touch f1

we have docker file --- changed to container through build command
docker build -t image3 .

image created --- next create to container--- through run command
docker run -it --name cont-3 image3 /bin/bash
ll
o/p: drwxr-xr-x   1 root root  66 Mar 17 00:26 etc/
-rw-r--r--   1 root root   0 Mar 17 00:25 f1
drwxr-xr-x   2 root root   6 Apr 18  2022 home/
drwxr-xr-x   2 root root   6 Mar 17 00:25 krishna/
exit
docker ps -a 

o/p: CONTAINER ID   IMAGE     COMMAND       CREATED          STATUS                      PORTS     NAMES
a9d11cbb6c7d   image3    "/bin/bash"   2 minutes ago    Exited (0) 27 seconds ago             cont-3
bed03854c602   image2    "/bin/bash"   25 minutes ago   Exited (0) 21 minutes ago             cont-2
504d3c0fc833   image1    "/bin/bash"   52 minutes ago   Exited (0) 50 minutes ago             cont-1

docker start cont-3
docker attach cont-3
cd krishna/
ll
cat>kittu
This is my volume-1
exit
docker ps -a

NOw we have cont-3 , in that cont-3 has kittu volume
Now it can be sharable to other containers

VOLUME SHARING:Automatic

docker login
username:divyatunuguntla
pwd:Prudhviraj467*
Credentials--- should dockerhub details

docker run -it --name cont-4 --privileged=true --volumes-from cont-3 image3 /bin/bash
cd krishna/
ll
cat kittu

we have cont-3 and volume is kittu ----- shared to cont-4 and having same volume of kittu
Now if we are going to do any changes in cont-4 of volume kittu --- changes will reflect in cont-3 of volume kittu

now in cont-4 ---krishna file--->    root@f3ff672954a1:/krishna# cat>krishna1
This is modified content
exit

docker ps -a
docker start cont-3
docker attach cont-3
 cd krishna/
 ll
 cat krishna1
 This is modified content
 
 if wnat to know which containers having volumes:
  docker container inspect cont-1
  
  delete the images : docker rmi <your-image-id>
  docker image prune
  
  DOCKER PORTS: Connecting jenkins with port number by using docker
  
  yum install docker -y
  docker --version
  service docker start
  service docker status
  docker images
  docker ps -a
  docker pull jenkinsci/jenkins
  docker run -it --name cont-1 jenkinsci/jenkins /bin/bash
  exit
  docker inspect jenkinsci/jenkins
  We need to assign the port number
  docker run -p 8080:8080 -p 5000:5000 jenkinsci/jenkins
  o/p: This may also be found at: /var/jenkins_home/secrets/initialAdminPassword
  copy public ip address and paste it in url:8080 --- we will get jenkins login page and paste the password
  
  Google search commands:
  
sudo yum update -y                             # To update all packages
sudo amazon-linux-extras install docker        # To install docker latest version
sudo service docker start                      # To start docker service
sudo service docker status                     # To check status of docker service. If it's running or not.
sudo systemctl enable docker                   # To ensure that docker service start after each reboot 
sudo usermod -a -G docker ec2-user             # To add ec2-user to docker group

for detailed explanation: https://www.geeksforgeeks.org/how-to-setup-jenkins-in-docker-container/


  
  Exec and Attach:
  
  Attach is used for go inside of the container
  Exec is also used for go inside of the container but creates the new process for entering the container
  ppid : parent process id ,pid: process id
  
  Expose and Public:
  
  3 ways: 1. Neither specify expose nor -p:---- that service in the container will only be accessible from inside of the container itself
  
          2. Only specifies expose : if you expose a port  -- the service in the container is not accessible from outside of docker,but from inside other docker      
             containers, this is good for inner docker container communication.    
           
          3. specify expose and -p : ---- the service in the container is accessible from anywhere,even outside of the docker
          
          If u do -p only but do not expose ---- docker does an implict expose.this is becoz if a port is oen to the public ,it is automatically open to the other      docker containers.
  
  
 DOCKER PUSH:
 
 image----container(some editings)----image----docker hub
 //// in ubuntu default we didn't get vim and default we get nano////
 
 
 docker pull ubuntu
 docker images
 docker run -it --name cont-5  ubuntu /bin/bash
 cd /tmp/
 touch d1 d2 d3 d4
 ll
 apt update -y
 apt install git -y
 apt install tree vim -y
 exit
 docker images
 wana build image from container -- will use committ command:
 Already we have an container -- cont-push and can be changing to image --- ubuntu-1
 
 docker commit cont-push ubuntu-1
 docker images
 
 docker hub pushing: 
 docker login : divyatunuguntla
 Prudhviraj467*
 
 ////IN git to github , if we want push the code , we will do commit, in the same way we need to do tag in docker////
 
 docker tag imagename reponame
 docker tag ubuntu-1 divyatunuguntla/chocolatefile
 docker images
 docker push divyatunuguntla/chocolatefile
 
 OTHER COMMANDS:
 
 docker images
 docker ps 
 docker ps -a
 To stop all the containers which are in start mode: docker stop $(docker ps -a -q)
 To delete all stopped containers: docker rm $(docker ps -a -q)
 to delete all images : docker rmi -f $(docker images -q)
 
 DOCKER SWARM:
 Container Management
 cluster is collection of nodes 
 Managing of clusters
 Swarm worker and Swarm Manager
 
 
 Docker engine creates --- docker swarm manager ----creates swarm worker nodes

Docker Swarm Components:

Service: Represents a part of the feature of an application
Task: A single part of work
Manager: This manages the work among the different nodes.
Worker : Which works for a specific purpose of the service

INFRASTRUCTURE OF THE SWARM:

1. CREATE 3 NODES 1---MANAGER , 2 ---WORKER NODES.

sudo -i
sudo yum update -y
docker --version
service docker start
service docker status
docker swarm init --advertise-addr 18.217.78.75   Here: master docker public ip address
o/p: Swarm initialized: current node (hitqijfsti08sqqr2flyughdk) is now a manager.

To add a worker to this swarm, run the following command:

    docker swarm join --token SWMTKN-1-2jrhrpvnn2d5u4pvjz1l096quqmoz2sp4vfmz4qkorzpiblo54-2qpll8ffcqvqzai9doppki2wd 18.217.78.75:2377

To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions. 


// If we have error on connecting the same nodde as manager --leave the swarm

docker swarm leave --force
Do same process again : docker swarm init --advertise-addr 18.217.78.75   Here: master docker public ip address


wana know the ports running on EC2 : netstat -tulpn | grep LISTEN

docker swarm join --token SWMTKN-1-61gnpq745hvigyc3zj2zc12oukr3e2a1ug846uahi6n6ok3ett-161vg26o9jvlngmvvqbld8mnu 18.217.78.75:2377

want to know how many nodes are connected to manager

   > docker node ls 

 
 o/p: ID                            HOSTNAME                                      STATUS    AVAILABILITY   MANAGER STATUS   ENGINE VERSION
turdjsbifukpppzg4eb4n1zw6     ip-172-31-13-56.us-east-2.compute.internal    Ready     Active                          20.10.17
w0thfgtynwy60lmwfhz87i1j1     ip-172-31-39-219.us-east-2.compute.internal   Ready     Active                          20.10.17
z2ps7x2j0hdj84du4cew4ta3a *   ip-172-31-43-54.us-east-2.compute.internal    Ready     Active         Leader           20.10.17

> details of manager /nodes: docker info

Permanently delete the node:

master node >docker node rm node -id 

docker swarm leave

to delete permanently docker node: docker node rm dockernode-id

To delete the manager forcefully:

docker swarm leave --force

docker swarm join-token worker  ---------------> it gives the worker token
docker swarm join-token manager -------------------> it give the manager token



CREATING A SERVICE ON SWARM:


Service: service is nothing but a container
We have replicas , if one service is down ,other will work as backup

create a service : > docker service

create a docker service: docker service create --name mtickets --replicas 3 --publish 80:80 httpd

Here: mtickets is the servicename , replicas : h/w many nodes ,httpd---image name

docker service ls

o/p: ID             NAME       MODE         REPLICAS   IMAGE          PORTS
lu3p5wy5u4hn   mtickets   replicated   3/3        httpd:latest   *:80->80/tcp

for service creation automatically container creates: docker ps -a

docker ps  ---- container is up , normally container is down but when service is created and container automatically creates as up.

To remove all services:

docker rm -f servicename  or /

docker rm -f containerID

Wnana see the service in physically : copy public IP and paste in browser:80

inspect the container: docker inspect containerID
inspect service: docker service inspect --pretty servicename -----o/p: is json formate
docker service inspect servicename -----o/p: is YAML formate



DOCKER STACK:

It is used to launch whole software together
you will write all the services and launch them together

docker stack deploy -c demo.yml demostack

demo.yml---name of the file , demostack ---name of stack
vim demo.yml
docker compose install search in google chrome ---- in this page we will get the installation commands :https://docs.docker.com/compose/install/other/

To download and install Compose standalone, run
curl -SL https://github.com/docker/compose/releases/download/v2.16.0/docker-compose-linux-x86_64 -o /usr/local/bin/docker-compose ---------docker compose installation
chmod +x /usr/local/bin/docker-compose  ------------------giving permissions
ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose ----------creating link for compose
docker compose --version
rm -rf *
vim docker-compose.yml
version: '3'
services:
   webapp1:
     image: nginx
     ports:
       - "8000:80"  

8000 ------is going to map ur container ,  80: ----port tcp

docker-compose up ------------------all the appications we wana run can be placed in yml file and that file is going to run by using the command up.

copy public ip address and paste in browser with :8000 and we will get the ngix page

///// If wana get 2 ngix in the browser:

vim docker-compose.yml
version: '3'
services:
   webapp1:
     image: nginx
     ports:
       - "8000:80"
   webapp2:
     image: nginx
     ports:
     ports:
       - "8001:80" 
 docker-compose up
 same copy public ip :8001 ----we will see the ngix page
 docker images
 we will see the ngix --- automatically creates the image
 
 /// if we want any commands related to docker compose ----------docker-compose --help
       
       
docker compose detailed explanation: https://docs.docker.com/compose/gettingstarted/

wana stop your services: docker-compose stop

You can bring everything down, removing the containers entirely, with the down command. Pass --volumes to also remove the data volume used by the Redis container:
docker compose down --volumes



DOCKER PORTS:

installing jenkins fron docker hub to docker :

docker pull jenkinsci/jenkins -----here : this command available in docker hub directly as an image with all the dependencies in our local docker

docker run -it --name cont-9 jenkinsci/jenkins /bin/bash
docker run -p 8080:8080 -p 5000:5000 jenkinsci/jenkins

01453a65026044109d0f08364694ceaf

This may also be found at: /var/jenkins_home/secrets/initialAdminPassword

copy public ip and paste in browser with Public ip of docker master:8080 ---we will get jenkins page to login and paste the admin password here

want to come to root user ---control+c
 
 
KUBERNETES:K8S ---CONTAINER MANAGEMENT TOOL

Container Management
Automates - Container deployment,container scaling and Load Balancing
It schedules,runs and manages isolated containers which are running on virtual/physical/cloud machines
It is supported by all the cloud providers
Google introduces K8s as an open source
k8s uses Go-lang
docker also Go-lang
Cloud Native Computing Foundation---donated by Google

 
 



 





 

 
 
 



 
   
   
